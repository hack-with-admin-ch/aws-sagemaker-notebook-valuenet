{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41037c25",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aac3b4",
   "metadata": {},
   "source": [
    "Change to `valuenet` directory and add `src` path to `PYTHONPATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdcade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ec2-user/SageMaker/valuenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602fe53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/ec2-user/SageMaker/valuenet/src')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea086a",
   "metadata": {},
   "source": [
    "Read environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdeefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_API_SECRET=%env NER_API_SECRET\n",
    "API_KEY=%env API_KEY\n",
    "DB_USER=%env DB_USER\n",
    "DB_PW=%env DB_PW\n",
    "DB_HOST=%env DB_HOST\n",
    "DB_PORT=%env DB_PORT\n",
    "DB_SCHEMA=\"public\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7af872",
   "metadata": {},
   "source": [
    "# Prepare & Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3f2d9b",
   "metadata": {},
   "source": [
    "## Add your custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c16b59",
   "metadata": {},
   "source": [
    "An example of custom data preparation can be found in statbot repository: [generate_sql_statments_and_questions.ipynb](https://github.com/statistikZH/statbot/blob/main/hackathon_hackzurich/generate_sql_statments_and_questions.ipynb). In this repository, random values are taken from the hack_zurich database and fed through a template to generate questions and queries.\n",
    "We then convert these questions and queries in the required format and save them as \n",
    "- statbot/hackathon_hackzurich/handmade_data_dev.json\n",
    "- statbot/hackathon_hackzurich/handmade_data_train.json\n",
    "\n",
    "If you wish to then preprocess these generated data, copy the handmade_data_xxx.json from statbot to valuenet:\n",
    "- valuenet/data/hack_zurich/handmade_training_data/handmade_data_dev.json'\n",
    "- valuenet/data/hack_zurich/handmade_training_data/handmade_data_train.json'\n",
    "\n",
    "You are now ready to preprocess the dataset by running the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e1c3fa",
   "metadata": {},
   "source": [
    "**Note**: If you decide to create your own query template, make sure to be very careful of the syntax and stay close to the one in the example notebook as valuenet codebase is quite sensible to the queries. For instance, \n",
    "- as it tokenize the SQL queries based on spaces, make sure to always add spaces everywhere (T1.year=2006 will error and sould be replaced with T1.year = 2006)\n",
    "- always put the keyword 'AS' when using shortcut names\n",
    "\n",
    "If you have errors in the next step, it is probably because of one of this reason. If error persist, check the effect of the function `tokenize()` in `valuenet/src/spider/test_suite_eval/process_sql.py` and adapt the codebase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff0f3ef",
   "metadata": {},
   "source": [
    "## Transform into Spider representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/tools/training_data_builder/training_data_builder.py --data hack_zurich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a0a9c9",
   "metadata": {},
   "source": [
    "You will now find your custom data in the two files [data/hack_zurich/original/train.json](data/hack_zurich/original/train.json) and [data/hack_zurich/original/dev.json](data/hack_zurich/original/dev.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ce2c8a",
   "metadata": {},
   "source": [
    "## Extract Value Candidates using Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/named_entity_recognition/api_ner/extract_values.py --data_path=data/hack_zurich/original/train.json --output_path=data/hack_zurich/ner_train.json --ner_api_secret={NER_API_SECRET}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a7de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/named_entity_recognition/api_ner/extract_values.py --data_path=data/hack_zurich/original/dev.json --output_path=data/hack_zurich/ner_dev.json --ner_api_secret={NER_API_SECRET}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b25ad3",
   "metadata": {},
   "source": [
    "## Extract the ground truth values from the SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/tools/get_values_from_sql.py --data_path data/hack_zurich/original/train.json --table_path data/hack_zurich/original/tables.json --ner_path data/hack_zurich/ner_train.json\n",
    "%run src/tools/get_values_from_sql.py --data_path data/hack_zurich/original/dev.json --table_path data/hack_zurich/original/tables.json --ner_path data/hack_zurich/ner_dev.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92125a24",
   "metadata": {},
   "source": [
    "This last script doesn't create a new file, but adds the ground truth values to the *ner_dev.json* and *ner_train.json* files, see the new attribute *values*:\n",
    "\n",
    "```json\n",
    "    \"values\": [\n",
    "      \"Wetzikon\",\n",
    "      \"2016\"\n",
    "    ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f33dc",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945fb03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/preprocessing/pre_process.py --data_path=data/hack_zurich/original/train.json --ner_data_path=data/hack_zurich/ner_train.json --table_path=data/hack_zurich/original/tables.json --output=data/hack_zurich/preprocessed_train.json --database_host={DB_HOST} --database_port={DB_PORT} --database_user={DB_USER} --database_password={DB_PW} --database_schema={DB_SCHEMA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9080d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/preprocessing/pre_process.py --data_path=data/hack_zurich/original/dev.json --ner_data_path=data/hack_zurich/ner_dev.json --table_path=data/hack_zurich/original/tables.json --output=data/hack_zurich/preprocessed_dev.json --database_host={DB_HOST} --database_port={DB_PORT} --database_user={DB_USER} --database_password={DB_PW} --database_schema={DB_SCHEMA}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87d6e9",
   "metadata": {},
   "source": [
    "## Modelling JOINs and SQL-to-SemQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b37f96",
   "metadata": {},
   "source": [
    "We start by modeling some JOINs as filters (minor importance, has most probably no effect on your data - you might skip it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/preprocessing/model_joins_as_filter.py --data_path=data/hack_zurich/preprocessed_train.json --table_path=data/hack_zurich/original/tables.json --output=data/hack_zurich/preprocessed_with_joins_train.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162fef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/preprocessing/model_joins_as_filter.py --data_path=data/hack_zurich/preprocessed_dev.json --table_path=data/hack_zurich/original/tables.json --output=data/hack_zurich/preprocessed_with_joins_dev.json "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b24ad",
   "metadata": {},
   "source": [
    "And then transform SQL to SemQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/preprocessing/sql2SemQL.py --data_path data/hack_zurich/preprocessed_with_joins_train.json --table_path data/hack_zurich/original/tables.json --output data/hack_zurich/train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/preprocessing/sql2SemQL.py --data_path data/hack_zurich/preprocessed_with_joins_dev.json --table_path data/hack_zurich/original/tables.json --output data/hack_zurich/dev.json "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac32b9c",
   "metadata": {},
   "source": [
    "##### You should now be able to train with the train-01.ipynb notebook !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2939022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_valuenet",
   "language": "python",
   "name": "conda_valuenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
